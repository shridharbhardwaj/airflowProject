[2024-02-26T00:00:02.204+0000] {processor.py:161} INFO - Started process (PID=8983) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:00:02.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:00:02.206+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:00:02.205+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:00:03.037+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:00:03.038+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:00:03.211+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:00:18.430+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:00:18.419+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:00:18.433+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:00:18.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 16.254 seconds
[2024-02-26T00:00:48.582+0000] {processor.py:161} INFO - Started process (PID=9078) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:00:48.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:00:48.585+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:00:48.584+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:00:49.328+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:00:49.329+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:00:49.511+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:00:51.418+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:00:51.408+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:00:51.423+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:00:51.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.866 seconds
[2024-02-26T00:01:22.364+0000] {processor.py:161} INFO - Started process (PID=9141) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:01:22.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:01:22.366+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:01:22.366+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:01:23.178+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:01:23.179+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:01:23.317+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:01:25.171+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:01:25.161+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:01:25.174+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:01:25.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.833 seconds
[2024-02-26T00:01:55.282+0000] {processor.py:161} INFO - Started process (PID=9200) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:01:55.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:01:55.284+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:01:55.284+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:01:56.072+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:01:56.073+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:01:56.214+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:01:58.038+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:01:58.027+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:01:58.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:01:58.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.784 seconds
[2024-02-26T00:02:28.109+0000] {processor.py:161} INFO - Started process (PID=9262) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:02:28.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:02:28.111+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:02:28.111+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:02:28.994+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:02:28.994+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:02:29.171+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:02:30.576+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:02:30.568+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:02:30.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:02:30.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.493 seconds
[2024-02-26T00:03:01.571+0000] {processor.py:161} INFO - Started process (PID=9323) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:03:01.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:03:01.573+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:03:01.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:03:02.309+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:03:02.310+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:03:02.452+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:03:04.031+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:03:04.022+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:03:04.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:03:04.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.484 seconds
[2024-02-26T00:03:34.918+0000] {processor.py:161} INFO - Started process (PID=9381) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:03:34.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:03:34.921+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:03:34.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:03:35.751+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:03:35.752+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:03:36.052+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:03:38.125+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:03:38.116+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:03:38.128+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:03:38.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.230 seconds
[2024-02-26T00:04:08.447+0000] {processor.py:161} INFO - Started process (PID=9459) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:04:08.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:04:08.449+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:04:08.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:04:09.228+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:04:09.230+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:04:09.398+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:04:10.888+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:04:10.879+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:04:10.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:04:10.908+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.464 seconds
[2024-02-26T00:04:41.429+0000] {processor.py:161} INFO - Started process (PID=9525) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:04:41.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:04:41.431+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:04:41.431+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:04:42.118+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:04:42.119+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:04:42.321+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:04:43.911+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:04:43.895+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:04:43.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:04:43.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.507 seconds
[2024-02-26T00:05:14.812+0000] {processor.py:161} INFO - Started process (PID=9585) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:05:14.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:05:14.814+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:05:14.814+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:05:15.575+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:05:15.576+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:05:15.727+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:05:17.336+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:05:17.325+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:05:17.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:05:17.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.554 seconds
[2024-02-26T00:05:48.268+0000] {processor.py:161} INFO - Started process (PID=9644) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:05:48.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:05:48.270+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:05:48.270+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:05:49.043+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:05:49.044+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:05:49.199+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:05:51.080+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:05:51.067+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:05:51.082+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:05:51.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.835 seconds
[2024-02-26T00:06:21.773+0000] {processor.py:161} INFO - Started process (PID=9704) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:06:21.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:06:21.775+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:06:21.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:06:22.486+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:06:22.486+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:06:22.675+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:06:24.416+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:06:24.407+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:06:24.418+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:06:24.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.667 seconds
[2024-02-26T00:06:54.892+0000] {processor.py:161} INFO - Started process (PID=9762) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:06:54.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:06:54.894+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:06:54.893+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:06:55.671+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:06:55.672+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:06:55.819+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:06:57.276+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:06:57.267+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:06:57.280+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:06:57.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.412 seconds
[2024-02-26T00:07:27.423+0000] {processor.py:161} INFO - Started process (PID=9823) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:07:27.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:07:27.426+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:07:27.425+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:07:28.172+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:07:28.173+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:07:28.418+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:07:29.860+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:07:29.844+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:07:29.862+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:07:29.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.461 seconds
[2024-02-26T00:08:00.115+0000] {processor.py:161} INFO - Started process (PID=9880) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:08:00.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:08:00.117+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:08:00.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:08:00.854+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:08:00.854+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:08:01.029+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:08:03.105+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:08:03.094+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:08:03.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:08:03.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.016 seconds
[2024-02-26T00:08:34.035+0000] {processor.py:161} INFO - Started process (PID=9942) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:08:34.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:08:34.037+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:08:34.037+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:08:34.813+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:08:34.815+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:08:34.966+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:08:36.482+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:08:36.471+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:08:36.485+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:08:36.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.471 seconds
[2024-02-26T00:09:06.673+0000] {processor.py:161} INFO - Started process (PID=10003) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:09:06.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:09:06.676+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:09:06.675+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:09:07.582+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:09:07.583+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:09:07.847+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:09:09.877+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:09:09.867+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:09:09.880+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:09:09.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.229 seconds
[2024-02-26T00:09:40.010+0000] {processor.py:161} INFO - Started process (PID=10069) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:09:40.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:09:40.012+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:09:40.012+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:09:40.736+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:09:40.737+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:09:40.905+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:09:42.279+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:09:42.270+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:09:42.282+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:09:42.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.294 seconds
[2024-02-26T00:10:13.112+0000] {processor.py:161} INFO - Started process (PID=10130) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:10:13.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:10:13.114+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:10:13.114+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:10:13.922+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:10:13.922+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:10:14.116+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:10:16.351+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:10:16.341+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:10:16.354+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:10:16.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.262 seconds
[2024-02-26T00:10:46.536+0000] {processor.py:161} INFO - Started process (PID=10204) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:10:46.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:10:46.538+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:10:46.538+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:10:47.329+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:10:47.330+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:10:47.550+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:10:49.379+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:10:49.365+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:10:49.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:10:49.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.868 seconds
[2024-02-26T00:11:20.332+0000] {processor.py:161} INFO - Started process (PID=10268) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:11:20.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:11:20.334+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:11:20.334+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:11:21.084+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:11:21.085+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:11:21.246+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:11:23.108+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:11:23.098+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:11:23.110+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:11:23.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.799 seconds
[2024-02-26T00:11:54.077+0000] {processor.py:161} INFO - Started process (PID=10327) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:11:54.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:11:54.080+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:11:54.080+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:11:54.820+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:11:54.821+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:11:55.082+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:11:56.677+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:11:56.667+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:11:56.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:11:56.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.630 seconds
[2024-02-26T00:12:26.826+0000] {processor.py:161} INFO - Started process (PID=10384) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:12:26.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:12:26.829+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:12:26.828+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:12:27.516+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:12:27.518+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:12:27.782+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:12:29.678+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:12:29.661+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:12:29.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:12:29.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.879 seconds
[2024-02-26T00:13:00.361+0000] {processor.py:161} INFO - Started process (PID=10445) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:13:00.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:13:00.364+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:13:00.363+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:13:01.162+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:13:01.162+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:13:01.309+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:13:04.356+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:13:04.347+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:13:04.359+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:13:04.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 4.020 seconds
[2024-02-26T00:13:34.755+0000] {processor.py:161} INFO - Started process (PID=10506) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:13:34.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:13:34.758+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:13:34.758+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:13:35.501+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:13:35.501+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:13:35.641+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:13:37.206+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:13:37.196+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:13:37.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:13:37.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.476 seconds
[2024-02-26T00:14:07.680+0000] {processor.py:161} INFO - Started process (PID=10569) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:14:07.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:14:07.682+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:14:07.682+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:14:08.476+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:14:08.476+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:14:08.666+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:14:10.270+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:14:10.261+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:14:10.273+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:14:10.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.622 seconds
[2024-02-26T00:14:40.405+0000] {processor.py:161} INFO - Started process (PID=10632) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:14:40.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:14:40.407+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:14:40.407+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:14:41.200+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:14:41.200+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:14:41.374+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:14:42.835+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:14:42.825+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:14:42.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:14:42.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.453 seconds
[2024-02-26T00:15:12.914+0000] {processor.py:161} INFO - Started process (PID=10694) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:15:12.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:15:12.916+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:15:12.916+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:15:13.686+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:15:13.687+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:15:13.853+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:15:15.354+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:15:15.344+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:15:15.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:15:15.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.466 seconds
[2024-02-26T00:15:46.032+0000] {processor.py:161} INFO - Started process (PID=10751) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:15:46.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:15:46.034+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:15:46.033+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:15:47.871+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:15:47.871+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:15:48.003+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:15:49.446+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:15:49.438+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:15:49.450+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:15:49.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.442 seconds
[2024-02-26T00:16:19.555+0000] {processor.py:161} INFO - Started process (PID=10820) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:16:19.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:16:19.557+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:16:19.557+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:16:20.355+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:16:20.355+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:16:20.539+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:16:23.342+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:16:23.332+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:16:23.345+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:16:23.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.811 seconds
[2024-02-26T00:16:53.905+0000] {processor.py:161} INFO - Started process (PID=10891) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:16:53.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:16:53.908+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:16:53.907+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:16:54.753+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:16:54.753+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:16:54.957+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:16:56.713+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:16:56.704+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:16:56.716+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:16:56.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.835 seconds
[2024-02-26T00:17:27.437+0000] {processor.py:161} INFO - Started process (PID=10951) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:17:27.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:17:27.439+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:17:27.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:17:28.323+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:17:28.323+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:17:28.516+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:17:29.977+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:17:29.956+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:17:29.981+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:17:30.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.569 seconds
[2024-02-26T00:18:00.940+0000] {processor.py:161} INFO - Started process (PID=11010) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:18:00.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:18:00.942+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:18:00.942+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:18:01.828+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:18:01.830+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:18:01.998+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:18:03.885+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:18:03.875+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:18:03.888+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:18:03.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.969 seconds
[2024-02-26T00:18:33.962+0000] {processor.py:161} INFO - Started process (PID=11070) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:18:33.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:18:33.965+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:18:33.964+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:18:35.011+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:18:35.011+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:18:35.194+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:18:37.050+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:18:37.034+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:18:37.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:18:37.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.121 seconds
[2024-02-26T00:19:07.971+0000] {processor.py:161} INFO - Started process (PID=11136) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:19:07.972+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:19:07.974+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:19:07.974+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:19:09.028+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:19:09.029+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:19:09.219+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:19:10.769+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:19:10.756+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:19:10.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:19:10.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.824 seconds
[2024-02-26T00:19:41.500+0000] {processor.py:161} INFO - Started process (PID=11195) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:19:41.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:19:41.502+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:19:41.502+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:19:42.282+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:19:42.282+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:19:42.420+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:19:43.939+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:19:43.931+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:19:43.941+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:19:43.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.464 seconds
[2024-02-26T00:20:14.346+0000] {processor.py:161} INFO - Started process (PID=11257) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:20:14.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:20:14.349+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:20:14.349+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:20:15.420+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:20:15.420+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:20:15.573+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:20:17.793+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:20:17.776+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:20:17.798+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:20:17.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.488 seconds
[2024-02-26T00:20:47.919+0000] {processor.py:161} INFO - Started process (PID=11318) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:20:47.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:20:47.923+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:20:47.922+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:20:49.070+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:20:49.071+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:20:49.278+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:20:50.779+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:20:50.765+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:20:50.782+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:20:50.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.887 seconds
[2024-02-26T00:21:21.156+0000] {processor.py:161} INFO - Started process (PID=11376) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:21:21.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:21:21.159+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:21:21.158+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:21:21.976+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:21:21.977+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:21:22.158+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:21:23.726+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:21:23.704+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:21:23.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:21:23.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.601 seconds
[2024-02-26T00:21:54.376+0000] {processor.py:161} INFO - Started process (PID=11439) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:21:54.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:21:54.378+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:21:54.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:21:55.318+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:21:55.320+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:21:55.514+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:21:57.613+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:21:57.591+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:21:57.620+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:21:57.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.293 seconds
[2024-02-26T00:22:27.839+0000] {processor.py:161} INFO - Started process (PID=11506) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:22:27.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:22:27.845+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:22:27.844+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:22:29.492+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:22:29.493+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:22:29.721+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:22:31.858+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:22:31.849+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:22:31.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:22:31.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 4.052 seconds
[2024-02-26T00:23:02.513+0000] {processor.py:161} INFO - Started process (PID=11576) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:23:02.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:23:02.516+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:23:02.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:23:03.834+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:23:03.835+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:23:04.046+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:23:05.791+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:23:05.781+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:23:05.794+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:23:05.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.304 seconds
[2024-02-26T00:23:36.092+0000] {processor.py:161} INFO - Started process (PID=11635) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:23:36.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:23:36.094+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:23:36.094+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:23:37.121+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:23:37.122+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:23:37.307+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:23:38.803+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:23:38.790+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:23:38.807+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:23:38.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.742 seconds
[2024-02-26T00:24:09.205+0000] {processor.py:161} INFO - Started process (PID=11701) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:24:09.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:24:09.207+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:24:09.207+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:24:10.468+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:24:10.469+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:24:10.772+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:24:12.435+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:24:12.413+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:24:12.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:24:12.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.257 seconds
[2024-02-26T00:24:42.619+0000] {processor.py:161} INFO - Started process (PID=11761) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:24:42.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:24:42.622+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:24:42.621+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:24:43.561+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:24:43.562+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:24:43.759+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:24:45.378+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:24:45.364+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:24:45.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:24:45.402+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.788 seconds
[2024-02-26T00:25:16.335+0000] {processor.py:161} INFO - Started process (PID=11820) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:25:16.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:25:16.337+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:25:16.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:25:17.220+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:25:17.220+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:25:17.401+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:25:18.939+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:25:18.921+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:25:18.945+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:25:18.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.640 seconds
[2024-02-26T00:25:49.406+0000] {processor.py:161} INFO - Started process (PID=11877) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:25:49.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:25:49.409+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:25:49.408+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:25:50.299+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:25:50.299+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:25:50.496+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:25:52.026+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:25:52.018+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:25:52.029+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:25:52.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 2.647 seconds
[2024-02-26T00:26:22.464+0000] {processor.py:161} INFO - Started process (PID=11943) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:26:22.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:26:22.470+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:26:22.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:26:22.833+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:26:22.825+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 17
    results_to_fetch=10
    ^
IndentationError: unexpected indent
[2024-02-26T00:26:22.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:26:22.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.400 seconds
[2024-02-26T00:26:53.695+0000] {processor.py:161} INFO - Started process (PID=12000) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:26:53.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:26:53.698+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:26:53.697+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:26:54.478+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:26:54.479+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:26:54.612+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:26:54.601+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:26:54.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:26:54.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.942 seconds
[2024-02-26T00:27:25.002+0000] {processor.py:161} INFO - Started process (PID=12058) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:27:25.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:27:25.005+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:27:25.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:27:25.812+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:27:25.813+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:27:26.128+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:27:26.118+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:27:26.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:27:26.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.152 seconds
[2024-02-26T00:27:56.505+0000] {processor.py:161} INFO - Started process (PID=12115) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:27:56.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:27:56.508+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:27:56.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:27:57.461+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:27:57.462+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:27:57.624+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:27:57.611+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:27:57.627+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:27:57.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.151 seconds
[2024-02-26T00:28:27.887+0000] {processor.py:161} INFO - Started process (PID=12172) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:28:27.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:28:27.890+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:28:27.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:28:28.693+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:28:28.694+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:28:28.968+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:28:28.956+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:28:28.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:28:28.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.106 seconds
[2024-02-26T00:28:59.541+0000] {processor.py:161} INFO - Started process (PID=12232) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:28:59.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:28:59.543+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:28:59.543+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:29:00.376+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:29:00.377+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:29:00.651+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:29:00.641+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:29:00.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:29:00.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.135 seconds
[2024-02-26T00:29:30.993+0000] {processor.py:161} INFO - Started process (PID=12292) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:29:30.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:29:30.995+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:29:30.995+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:29:31.786+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:29:31.786+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:29:31.945+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:29:31.934+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:29:31.947+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:29:31.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.976 seconds
[2024-02-26T00:30:02.803+0000] {processor.py:161} INFO - Started process (PID=12355) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:30:02.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:30:02.806+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:30:02.806+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:30:03.709+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:30:03.710+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:30:03.971+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:30:03.961+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 56, in <module>
    s3.Bucket('airflow-bucket-data').upload_file(Filename='random_user_data.csv')
AttributeError: 's3.Bucket' object has no attribute 'uppload_file'
[2024-02-26T00:30:03.978+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:30:04.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.208 seconds
[2024-02-26T00:30:34.568+0000] {processor.py:161} INFO - Started process (PID=12412) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:30:34.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:30:34.571+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:30:34.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:30:35.586+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:30:35.586+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:30:35.729+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:30:35.714+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 56, in <module>
    s3.Bucket('airflow-bucket-data').upload_file(Filename='random_user_data.csv')
TypeError: bucket_upload_file() missing 1 required positional argument: 'Key'
[2024-02-26T00:30:35.733+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:30:35.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.188 seconds
[2024-02-26T00:31:05.913+0000] {processor.py:161} INFO - Started process (PID=12473) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:31:05.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:31:05.916+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:31:05.916+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:31:06.797+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:31:06.797+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:31:09.073+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:31:12.055+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:31:12.044+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:31:12.058+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:31:12.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 6.167 seconds
[2024-02-26T00:31:42.167+0000] {processor.py:161} INFO - Started process (PID=12551) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:31:42.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:31:42.170+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:31:42.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:31:42.927+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:31:42.928+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:31:44.590+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:31:45.985+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:31:45.973+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:31:45.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:31:46.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.843 seconds
[2024-02-26T00:32:16.715+0000] {processor.py:161} INFO - Started process (PID=12612) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:32:16.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:32:16.717+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:32:16.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:32:17.606+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:32:17.606+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:32:19.389+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:32:21.515+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:32:21.502+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:32:21.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:32:21.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 4.843 seconds
[2024-02-26T00:32:51.704+0000] {processor.py:161} INFO - Started process (PID=12671) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:32:51.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:32:51.711+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:32:51.710+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:32:54.147+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:32:54.148+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:32:56.674+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:32:59.371+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:32:59.359+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:32:59.373+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:32:59.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 7.701 seconds
[2024-02-26T00:33:29.470+0000] {processor.py:161} INFO - Started process (PID=12740) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:33:29.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:33:29.472+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:33:29.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:33:31.185+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:33:31.187+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:33:32.946+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:33:34.596+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:33:34.583+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:33:34.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:33:34.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 5.158 seconds
[2024-02-26T00:34:04.893+0000] {processor.py:161} INFO - Started process (PID=12802) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:34:04.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:34:04.896+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:34:04.896+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:34:06.013+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:34:06.014+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:34:07.995+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:34:09.680+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:34:09.667+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:34:09.686+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:34:09.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 4.820 seconds
[2024-02-26T00:34:39.907+0000] {processor.py:161} INFO - Started process (PID=12880) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:34:39.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:34:39.910+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:34:39.910+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:34:40.697+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:34:40.698+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:34:42.354+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:34:43.819+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:34:43.799+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:34:43.823+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:34:43.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 3.943 seconds
[2024-02-26T00:35:13.929+0000] {processor.py:161} INFO - Started process (PID=12943) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:35:13.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:35:13.931+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:35:13.931+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:35:14.753+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:35:14.754+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:35:16.675+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:35:18.295+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:35:18.287+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 58, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:35:18.299+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:35:18.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 4.392 seconds
[2024-02-26T00:35:48.751+0000] {processor.py:161} INFO - Started process (PID=13007) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:35:48.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:35:48.754+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:35:48.753+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:35:49.523+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:35:49.524+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:35:49.685+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:35:49.676+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:35:49.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:35:49.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.959 seconds
[2024-02-26T00:36:20.316+0000] {processor.py:161} INFO - Started process (PID=13066) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:36:20.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:36:20.320+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:36:20.320+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:36:21.236+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:36:21.236+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:36:21.585+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:36:21.565+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:36:21.588+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:36:21.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.301 seconds
[2024-02-26T00:36:52.039+0000] {processor.py:161} INFO - Started process (PID=13123) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:36:52.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:36:52.041+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:36:52.041+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:36:52.856+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:36:52.856+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:36:53.024+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:36:53.006+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:36:53.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:36:53.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.009 seconds
[2024-02-26T00:37:23.778+0000] {processor.py:161} INFO - Started process (PID=13182) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:37:23.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T00:37:23.780+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:37:23.780+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:37:24.585+0000] {logging_mixin.py:188} INFO - airflow-bucket-data
[2024-02-26T00:37:24.586+0000] {logging_mixin.py:188} INFO - project-d-testing
[2024-02-26T00:37:24.783+0000] {logging_mixin.py:188} INFO - [2024-02-26T00:37:24.765+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/user_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 236, in get_filesystem_class
    register_implementation(protocol, _import_class(bit["class"]))
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 271, in _import_class
    mod = importlib.import_module(mod)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 's3fs'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/user_data_dag.py", line 5, in <module>
    from random_user_api import run_userdata_etl
  File "/opt/airflow/dags/random_user_api.py", line 3, in <module>
    import config
  File "/opt/airflow/dags/config.py", line 54, in <module>
    df.to_csv("s3://airflow-bucket-data/random_user_data.csv")
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 716, in get_handle
    ioargs = _get_filepath_or_buffer(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/common.py", line 414, in _get_filepath_or_buffer
    file_obj = fsspec.open(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 459, in open
    out = open_files(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 283, in open_files
    fs, fs_token, paths = get_fs_token_paths(
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 623, in get_fs_token_paths
    chain = _un_chain(urlpath0, storage_options or {})
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/core.py", line 332, in _un_chain
    cls = get_filesystem_class(protocol)
  File "/home/airflow/.local/lib/python3.8/site-packages/fsspec/registry.py", line 238, in get_filesystem_class
    raise ImportError(bit["err"]) from e
ImportError: Install s3fs to access S3
[2024-02-26T00:37:24.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T00:37:24.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.029 seconds
[2024-02-26T01:22:56.131+0000] {processor.py:161} INFO - Started process (PID=34) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:22:56.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:22:56.138+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:22:56.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:22:59.683+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:23:00.043+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:00.042+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:23:00.121+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:00.120+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:23:00.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 4.124 seconds
[2024-02-26T01:23:30.518+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:23:30.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:23:30.522+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:30.522+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:23:31.139+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:23:31.232+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:31.232+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:23:31.242+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:31.241+0000] {dag.py:3058} INFO - Creating ORM DAG for user_data_dag
[2024-02-26T01:23:31.250+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:31.250+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:23:31.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.758 seconds
[2024-02-26T01:23:33.435+0000] {processor.py:161} INFO - Started process (PID=102) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:23:33.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:23:33.439+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:33.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:23:34.219+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:23:34.231+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:34.230+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:23:34.259+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:23:34.258+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:23:34.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.858 seconds
[2024-02-26T01:24:05.039+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:24:05.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:24:05.043+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:24:05.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:24:05.638+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:24:05.655+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:24:05.655+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:24:05.672+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:24:05.672+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:24:05.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.658 seconds
[2024-02-26T01:24:36.221+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:24:36.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:24:36.225+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:24:36.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:24:36.869+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:24:36.885+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:24:36.884+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:24:36.905+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:24:36.905+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:24:36.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.710 seconds
[2024-02-26T01:25:07.155+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:25:07.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:25:07.162+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:25:07.161+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:25:07.971+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:25:08.139+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:25:08.139+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:25:08.170+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:25:08.170+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:25:08.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.053 seconds
[2024-02-26T01:25:38.727+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:25:38.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:25:38.730+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:25:38.730+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:25:39.481+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:25:39.504+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:25:39.503+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:25:39.530+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:25:39.530+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:25:39.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.834 seconds
[2024-02-26T01:26:09.717+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:26:09.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:26:09.720+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:26:09.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:26:10.320+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:26:10.337+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:26:10.336+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:26:10.357+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:26:10.357+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:26:10.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.666 seconds
[2024-02-26T01:26:40.467+0000] {processor.py:161} INFO - Started process (PID=456) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:26:40.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:26:40.471+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:26:40.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:26:41.268+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:26:41.290+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:26:41.289+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:26:41.312+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:26:41.312+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:26:41.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.874 seconds
[2024-02-26T01:27:11.416+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:27:11.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:27:11.421+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:27:11.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:27:12.281+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:27:12.298+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:27:12.298+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:27:12.319+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:27:12.319+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:27:12.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.933 seconds
[2024-02-26T01:27:42.439+0000] {processor.py:161} INFO - Started process (PID=572) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:27:42.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:27:42.443+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:27:42.442+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:27:43.114+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:27:43.131+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:27:43.130+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:27:43.175+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:27:43.174+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:27:43.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.763 seconds
[2024-02-26T01:28:13.540+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:13.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:28:13.543+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:13.543+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:14.125+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:14.142+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:14.141+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:28:14.162+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:14.162+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:28:14.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.646 seconds
[2024-02-26T01:28:39.940+0000] {processor.py:161} INFO - Started process (PID=676) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:39.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:28:39.943+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:39.942+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:40.521+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:40.613+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:40.613+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:28:40.633+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:40.632+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:28:40.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.724 seconds
[2024-02-26T01:28:47.189+0000] {processor.py:161} INFO - Started process (PID=697) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:47.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:28:47.192+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:47.192+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:47.827+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:28:47.838+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:47.837+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:28:47.864+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:28:47.864+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:28:47.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.704 seconds
[2024-02-26T01:29:17.979+0000] {processor.py:161} INFO - Started process (PID=760) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:17.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:29:17.986+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:17.985+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:18.682+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:18.784+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:18.783+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:29:18.804+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:18.803+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:29:18.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.857 seconds
[2024-02-26T01:29:20.458+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:20.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:29:20.461+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:20.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:21.068+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:21.080+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:21.080+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:29:21.100+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:21.100+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:29:21.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.671 seconds
[2024-02-26T01:29:52.153+0000] {processor.py:161} INFO - Started process (PID=827) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:52.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:29:52.156+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:52.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:52.845+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:29:52.943+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:52.942+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:29:52.962+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:29:52.962+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:29:52.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.836 seconds
[2024-02-26T01:30:08.561+0000] {processor.py:161} INFO - Started process (PID=849) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:30:08.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:30:08.565+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:30:08.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:30:09.222+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:30:09.327+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:30:09.327+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:30:09.340+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:30:09.339+0000] {dag.py:3058} INFO - Creating ORM DAG for user_data_dag
[2024-02-26T01:30:09.352+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:30:09.352+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:30:09.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.822 seconds
[2024-02-26T01:30:40.214+0000] {processor.py:161} INFO - Started process (PID=908) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:30:40.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:30:40.218+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:30:40.217+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:30:41.065+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:30:41.097+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:30:41.096+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:30:41.132+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:30:41.132+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:30:41.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.955 seconds
[2024-02-26T01:31:11.422+0000] {processor.py:161} INFO - Started process (PID=965) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:31:11.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:31:11.427+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:31:11.427+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:31:12.240+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:31:12.378+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:31:12.377+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:31:12.401+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:31:12.401+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:31:12.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.003 seconds
[2024-02-26T01:31:43.102+0000] {processor.py:161} INFO - Started process (PID=1022) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:31:43.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:31:43.105+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:31:43.105+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:31:43.903+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:31:43.923+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:31:43.923+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:31:43.944+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:31:43.944+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:31:43.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.880 seconds
[2024-02-26T01:32:14.337+0000] {processor.py:161} INFO - Started process (PID=1079) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:32:14.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:32:14.341+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:32:14.340+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:32:14.964+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:32:14.981+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:32:14.980+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:32:15.003+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:32:15.002+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:32:15.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.687 seconds
[2024-02-26T01:32:45.112+0000] {processor.py:161} INFO - Started process (PID=1136) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:32:45.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:32:45.118+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:32:45.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:32:46.001+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:32:46.034+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:32:46.033+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:32:46.068+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:32:46.068+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:32:46.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.993 seconds
[2024-02-26T01:33:16.413+0000] {processor.py:161} INFO - Started process (PID=1194) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:33:16.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:33:16.416+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:33:16.416+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:33:16.984+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:33:17.000+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:33:17.000+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:33:17.020+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:33:17.020+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:33:17.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.631 seconds
[2024-02-26T01:33:47.878+0000] {processor.py:161} INFO - Started process (PID=1253) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:33:47.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:33:47.882+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:33:47.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:33:48.577+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:33:48.599+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:33:48.598+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:33:48.624+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:33:48.624+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:33:48.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.781 seconds
[2024-02-26T01:34:19.366+0000] {processor.py:161} INFO - Started process (PID=1310) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:34:19.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:34:19.369+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:34:19.368+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:34:20.039+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:34:20.060+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:34:20.059+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:34:20.088+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:34:20.087+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:34:20.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.751 seconds
[2024-02-26T01:34:36.399+0000] {processor.py:161} INFO - Started process (PID=1357) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:34:36.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:34:36.402+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:34:36.402+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:34:36.983+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:34:37.072+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:34:37.072+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:34:37.091+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:34:37.091+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:34:37.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.720 seconds
[2024-02-26T01:35:07.705+0000] {processor.py:161} INFO - Started process (PID=1414) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:35:07.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:35:07.711+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:35:07.710+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:35:08.369+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:35:08.386+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:35:08.385+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:35:08.407+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:35:08.407+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:35:08.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.728 seconds
[2024-02-26T01:35:38.952+0000] {processor.py:161} INFO - Started process (PID=1471) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:35:38.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:35:38.956+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:35:38.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:35:39.532+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:35:39.547+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:35:39.547+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:35:39.567+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:35:39.566+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:35:39.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.639 seconds
[2024-02-26T01:36:10.105+0000] {processor.py:161} INFO - Started process (PID=1531) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:36:10.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:36:10.109+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:36:10.109+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:36:11.118+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:36:11.142+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:36:11.142+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:36:11.178+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:36:11.178+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:36:11.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 1.114 seconds
[2024-02-26T01:36:41.418+0000] {processor.py:161} INFO - Started process (PID=1588) to work on /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:36:41.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/user_data_dag.py for tasks to queue
[2024-02-26T01:36:41.421+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:36:41.421+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:36:41.974+0000] {processor.py:840} INFO - DAG(s) 'user_data_dag' retrieved from /opt/airflow/dags/user_data_dag.py
[2024-02-26T01:36:41.990+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:36:41.989+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2024-02-26T01:36:42.009+0000] {logging_mixin.py:188} INFO - [2024-02-26T01:36:42.009+0000] {dag.py:3823} INFO - Setting next_dagrun for user_data_dag to 2024-02-26 00:00:00+00:00, run_after=2024-02-27 00:00:00+00:00
[2024-02-26T01:36:42.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/user_data_dag.py took 0.618 seconds
